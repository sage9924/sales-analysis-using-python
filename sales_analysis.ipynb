{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary Python libiraies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import plotly.express as px\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # Ignore all warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Product</th>\n",
       "      <th>Quantity Ordered</th>\n",
       "      <th>Price Each</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Purchase Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>176558</td>\n",
       "      <td>USB-C Charging Cable</td>\n",
       "      <td>2</td>\n",
       "      <td>11.95</td>\n",
       "      <td>04/19/19 08:46</td>\n",
       "      <td>917 1st St, Dallas, TX 75001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>176559</td>\n",
       "      <td>Bose SoundSport Headphones</td>\n",
       "      <td>1</td>\n",
       "      <td>99.99</td>\n",
       "      <td>04/07/19 22:30</td>\n",
       "      <td>682 Chestnut St, Boston, MA 02215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>176560</td>\n",
       "      <td>Google Phone</td>\n",
       "      <td>1</td>\n",
       "      <td>600</td>\n",
       "      <td>04/12/19 14:38</td>\n",
       "      <td>669 Spruce St, Los Angeles, CA 90001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>176560</td>\n",
       "      <td>Wired Headphones</td>\n",
       "      <td>1</td>\n",
       "      <td>11.99</td>\n",
       "      <td>04/12/19 14:38</td>\n",
       "      <td>669 Spruce St, Los Angeles, CA 90001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Order ID                     Product Quantity Ordered Price Each  \\\n",
       "0   176558        USB-C Charging Cable                2      11.95   \n",
       "1      NaN                         NaN              NaN        NaN   \n",
       "2   176559  Bose SoundSport Headphones                1      99.99   \n",
       "3   176560                Google Phone                1        600   \n",
       "4   176560            Wired Headphones                1      11.99   \n",
       "\n",
       "       Order Date                      Purchase Address  \n",
       "0  04/19/19 08:46          917 1st St, Dallas, TX 75001  \n",
       "1             NaN                                   NaN  \n",
       "2  04/07/19 22:30     682 Chestnut St, Boston, MA 02215  \n",
       "3  04/12/19 14:38  669 Spruce St, Los Angeles, CA 90001  \n",
       "4  04/12/19 14:38  669 Spruce St, Los Angeles, CA 90001  "
      ]
     },
     "execution_count": 2204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading dataset into python dataframe\n",
    "df = pd.read_csv('raw_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going through the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 186850 entries, 0 to 186849\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count   Dtype \n",
      "---  ------            --------------   ----- \n",
      " 0   Order ID          186305 non-null  object\n",
      " 1   Product           186305 non-null  object\n",
      " 2   Quantity Ordered  186305 non-null  object\n",
      " 3   Price Each        186305 non-null  object\n",
      " 4   Order Date        186305 non-null  object\n",
      " 5   Purchase Address  186305 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 8.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# going through the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order ID, Quantity Ordered, Price and Order date type have to be formatted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Order ID            545\n",
       "Product             545\n",
       "Quantity Ordered    545\n",
       "Price Each          545\n",
       "Order Date          545\n",
       "Purchase Address    545\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the total null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove null values from dataset\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format data type \n",
    "df['Order Date'] = pd.to_datetime(df['Order Date'],errors='coerce')\n",
    "df['Quantity Ordered'] = pd.to_numeric(df['Quantity Ordered'],errors='coerce')\n",
    "df['Price Each'] = pd.to_numeric(df['Price Each'],errors='coerce')\n",
    "df['Order ID'] = pd.to_numeric(df['Order ID'],errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Order ID            355\n",
       "Product               0\n",
       "Quantity Ordered    355\n",
       "Price Each          355\n",
       "Order Date          355\n",
       "Purchase Address      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2173,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2173], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# droping null values in both Quantity Ordered and Order ID\u001b[39;00m\n\u001b[0;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdropna(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuantity Ordered\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuantity Ordered\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m      4\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOrder ID\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOrder ID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# droping null values in both Quantity Ordered and Order ID\n",
    "df = df.dropna(inplace=True)\n",
    "df['Quantity Ordered'] = df['Quantity Ordered'].astype(int)\n",
    "df['Order ID'] = df['Order ID'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking duplicate\n",
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicated values from dataset\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting date, hour, day, weekofyear, month, and year from Order_date\n",
    "df['Hour'] = df['Order Date'].dt.hour # Hour of the day\n",
    "df['Day'] = df['Order Date'].dt.day_name() # Day of the month\n",
    "df['Month'] = df['Order Date'].dt.month_name() # name of the mohth in the year eg(january,febuary...)\n",
    "df['mon'] = df['Order Date'].dt.month # month_position in the year eg(1,2...)\n",
    "df['Year'] = df['Order Date'].dt.year # year\n",
    "df['Week_of_Year'] = df['Order Date'].dt.isocalendar().week #week of the year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking number of unique values in Product column\n",
    "df['Product'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define category patterns\n",
    "\n",
    "patterns = {\n",
    "    'Phone': r'Phone|iPhone',\n",
    "    'Accessories': r'Cable|Headphones|Batteries',\n",
    "    'Monitors': r'Monitor',\n",
    "    'Laptop':r'Laptop',\n",
    "    'TV':r'TV|Flatscreen',\n",
    "    'Appliances':r'Dryer|Washing Machine'\n",
    "    }\n",
    "\n",
    "# Function to categorize products based on patterns\n",
    "def categorize_products(products):\n",
    "    if pd.isnull(products):\n",
    "        return 'Other'\n",
    "    for category, pattern in patterns.items():\n",
    "        if re.search(pattern, products, re.IGNORECASE):\n",
    "            return category\n",
    "    return 'Other'\n",
    "\n",
    "# Apply categorization\n",
    "df['categorize'] = df['Product'].apply(categorize_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['categorize'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create revenue column by multiplying Quantity_Ordered  by Price_Each column\n",
    "df['Revenue'] = df['Quantity Ordered'] * df['Price Each']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting city from purchase address\n",
    "df['city'] = df['Purchase Address'].apply(lambda x: x.split(',')[1].strip())\n",
    "print(df['city'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data type well formated, \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the dataset is well cleaned up properly and processed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explotatrary Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sales Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Best Month for Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Month for Sales\n",
    "month_sales = df['Month'].value_counts().sort_values(ascending=False).reset_index()\n",
    "px.bar(month_sales,x='Month',y='count',title='Monthly sales')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### What day of the week has the highest sales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Week_of_Year into Week_of_Month (forcing a max of 4 weeks)\n",
    "df['Week_of_Month'] = df.groupby(['Year', 'mon'])['Week_of_Year'].rank(method='dense').astype(int)\n",
    "\n",
    "# If a month has a 5th week, merge it into the 4th week\n",
    "df.loc[df['Week_of_Month'] > 4, 'Week_of_Month'] = 4  \n",
    "\n",
    "# Group by Month, Week of Month, and Day of Week to get total Revenue (everyday sales calculation)\n",
    "weekly_sales = df.groupby(['mon', 'Week_of_Month', 'Day'], as_index=False)['Revenue'].sum()\n",
    "\n",
    "# Find the Best Sales Day per Week (Day with highest revenue in each week)\n",
    "best_sales_per_week = weekly_sales.loc[weekly_sales.groupby(['mon', 'Week_of_Month'])['Revenue'].idxmax()]\n",
    "print(best_sales_per_week.head(10))\n",
    "\n",
    "# Create a Bar Chart in Plotly\n",
    "px.bar(best_sales_per_week, x=\"Week_of_Month\", y=\"Revenue\", color=\"Day\", facet_col='mon', title=\"Best Sales Day in Each Week of Every Month\",\n",
    "      labels={\"Week_of_Month\": \"Week\", \"Revenue\": \"Total Sales\", \"Day\": \"Best Sales Day\"}, text=\"Day\", height=600, width=1400 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Timeline of Day of the Week vs. Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Week_of_Year into Week_of_Month (forcing a max of 4 weeks)\n",
    "df['Week_of_Month'] = df.groupby(['Year', 'mon'])['Week_of_Year'].rank(method='dense').astype(int)\n",
    "\n",
    "# If a month has a 5th week, merge it into the 4th week\n",
    "df.loc[df['Week_of_Month'] > 4, 'Week_of_Month'] = 4  \n",
    "\n",
    "# Group by Month, Week of Month, and Day of Week to get total Revenue (everyday sales calculation)\n",
    "weekly_sales = df.groupby(['mon', 'Week_of_Month', 'Hour'], as_index=False)['Revenue'].sum()\n",
    "\n",
    "# Find the Best Sales Day per Week (Day with highest revenue in each week)\n",
    "best_sales_per_week = weekly_sales.loc[weekly_sales.groupby(['mon', 'Week_of_Month'])['Revenue'].idxmax()]\n",
    "print(best_sales_per_week.head(15))\n",
    "\n",
    "# Create a Bar Chart in Plotly\n",
    "fig = px.bar(best_sales_per_week,x=\"Week_of_Month\",y=\"Revenue\",color=\"Hour\",facet_col='mon',title=\"Best Sales Hour in Each Week of Every Month\",\n",
    "    labels={\"Week_of_Month\": \"Week \", \"Revenue\": \"Sales\", \"Hour\": \"Best SalesHour\"},text=\"Hour\",height=600,width=1400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sales Per Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sales_per_hour = df.groupby('Hour')['Revenue'].sum().sort_values(ascending=False).reset_index()\n",
    "print(Sales_per_hour.head())\n",
    "\n",
    "px.bar(Sales_per_hour,x='Hour',y='Revenue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Product Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What Product Sold the Most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what product sold the most\n",
    "Product_sales = df['Product'].value_counts().sort_values(ascending=False).reset_index()\n",
    "print(Product_sales.head())\n",
    "px.bar(Product_sales,x='Product',y='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Top Products for Each City"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Top 5 Product with highest revenue for each city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by city and product to get total quantity ordered and revenue\n",
    "Cities_Product = df.groupby(['city', 'Product'], as_index=False).agg({'Quantity Ordered': 'sum','Revenue': 'sum'})\n",
    "\n",
    "# Rename columns for clarity\n",
    "Cities_Product.rename(columns={'Quantity Ordered': 'Orders Count'}, inplace=True)\n",
    "\n",
    "# Function to get top 5 products for each city\n",
    "def get_top_product(order):\n",
    "    return order.nlargest(5, 'Orders Count')  # Sort by order count\n",
    "\n",
    "# Apply function to find top 5 products per city\n",
    "Cities_Product = Cities_Product.groupby(['city'], group_keys=False).apply(get_top_product)\n",
    "\n",
    "# Create pivot tables for 'Revenue'\n",
    "pivot_orders = Cities_Product.pivot_table(index='city', values='Orders Count', columns='Product', fill_value=0).reset_index()\n",
    "print(\"Pivot Table: Orders Count\")\n",
    "pivot_orders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert pivot table to long format\n",
    "pivot_orders_long = pivot_orders.reset_index().melt(id_vars='city', var_name='Product', value_name='Orders Count')\n",
    "# Create bar chart\n",
    "px.bar(pivot_orders_long,x=\"city\",y=\"Orders Count\",color=\"Product\",barmode=\"group\",title=\"Top 5 Products Ordered in Each City\",\n",
    "    labels={\"city\": \"City\", \"Orders Count\": \"Total Orders\"},width=1400,height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Top 5 highest Product in each city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pivot tables for 'Revenue'\n",
    "pivot_orders = Cities_Product.pivot_table(index='city', values='Revenue', columns='Product', fill_value=0).reset_index()\n",
    "# Display the pivot tables\n",
    "print(\"Pivot Table: Revenue\")\n",
    "pivot_orders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pivot table to long format\n",
    "pivot_orders = pivot_orders.melt(id_vars='city',var_name='Product',value_name='Revenue')\n",
    "\n",
    "px.bar(pivot_orders,x='city',y='Revenue',color='Product',barmode='group',title='Top 5 Products Revenue in Each City',\n",
    "       labels={'city':'city','Revenue':'Total Revenue'},width=1000,height=500,)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What Products Are Most Often Sold Together?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "\n",
    "# Filter orders that contain multiple products\n",
    "multi_product_orders = df[df['Order ID'].duplicated(keep=False)]\n",
    "# Group products by 'Order ID'\n",
    "group_orders = multi_product_orders.groupby('Order ID')['Product'].apply(list)\n",
    "\n",
    "# Generate product pairs\n",
    "product_pairs = []\n",
    "for products in group_orders:\n",
    "    product_pairs.extend(combinations(sorted(products),2)) # sort to avoid duplicate pair variations\n",
    "#count most common product pairs\n",
    "pair_counts = Counter(product_pairs)\n",
    "#convert to DataFrame for easy analysis\n",
    "most_common_pairs = pd.DataFrame(pair_counts.most_common(10), columns=[\"Product Pair\", \"Count\"])\n",
    "\n",
    "print(most_common_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What Percentage of Orders Include Multiple Products?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_orders = df['Order ID'].nunique()  #count total order \n",
    "order_count = df['Order ID'].value_counts()      # Count the number of products per order\n",
    "\n",
    "multiple_id = order_count[order_count>1].count()     #count multiple order\n",
    "single_order = order_count[order_count == 1].count()    # Get Single Product Orders (where count is 1)\n",
    "\n",
    "percentage_multiple_order = (multiple_id/total_orders)*100   #find the percentage of multiple orde\n",
    "percentage_single = 100 -percentage_multiple_order       #percentage of single order\n",
    "\n",
    "#displays the output \n",
    "print(f'''\n",
    "    Total_orders = {total_orders}\\n\n",
    "    Multiple_order = {multiple_id}\\n\n",
    "    Single_order = {single_order}\\n\n",
    "    Multiple_order % = {percentage_multiple_order}\\n\n",
    "    Single_order % = {percentage_single}\n",
    "''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order Value Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What Was the Highest Single-Order Value?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_single_values  = df[df['Revenue'] == max(df['Revenue'])]\n",
    "highest_single_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### whict city has the higest Revenue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_higest_revenue = df.groupby('city',as_index=False).agg({'Order ID':'count','Revenue':'sum'})\n",
    "city_higest_revenue.rename(columns={'Order ID':'Order Count'},inplace=True)\n",
    "\n",
    "px.bar(city_higest_revenue,x='city',y='Revenue',title='Higest city Sales',width=1000,height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(city_higest_revenue)\n",
    "px.bar(city_higest_revenue,x='city',y='Order Count',title='Higest city Sales',width=1000,height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### What Is the Distribution of States?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_distribution = df['city'].value_counts().reset_index()\n",
    "print(city_distribution)\n",
    "px.pie(city_distribution,values='count',names='city')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
